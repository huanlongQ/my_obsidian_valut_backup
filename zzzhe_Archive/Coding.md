# 2. Linux Comm
# 4. git

git is a version control and collaborative tool for projects. I do not need git now. 

# 5. TeNPy

[Introduction Overview of tenpy](https://tenpy.readthedocs.io/en/latest/intro/overview.html)
~~~
simulations: run the below. 
algotithms: like DMRG, TEBD, TDVP
models: like Hubbard, TFIM, Heisenberg
networks: like MPS, MPO
linalg
~~~

# 6. GPU and CPU

Absolutely â€” understanding **what GPUs _canâ€™t_ do efficiently** is _crucial_ when writing high-performance code, especially for algorithms like the Wolff cluster update. Letâ€™s break it down precisely and clearly.

---

## âœ… What GPUs _are great_ at:

GPUs excel at **SIMD** (Single Instruction, Multiple Data) workloads:

- Regular, large-scale numerical computation
    
- Uniform operations on arrays (e.g., matrix multiplication, CNNs)
    
- No or minimal branching (everyone does the same thing)
    
- High memory _throughput_ when access is **contiguous and aligned**

---

## âŒ What GPUs **cannot do efficiently**

### 1. **Irregular control flow (branching logic)**

- When threads in a warp (usually 32 threads) **diverge** (e.g., some go into `if`, others don't), the GPU **serializes** the branches.
    
- Example: `if spin == old_spin and rand < p_add:` â€” some threads might pass, some wonâ€™t â†’ warp divergence â†’ slow

ğŸ§  Analogy: Like a group of people crossing a street together, but each one deciding to take a different path.

---

### 2. **Recursive or dynamic-sized operations**

- Cluster growth (like Wolff or BFS-style algorithms) grows **dynamically**.
    
- GPUs **prefer fixed-size operations** â€” anything like:
    
    - Growing lists
        
    - Variable iteration loops (`while len(queue) > 0:`)
        
    - Recursion ...is **bad fit**.

---

### 3. **Random memory access (non-contiguous loads/stores)**

- GPUs are fast when accessing data like: `spins[:, :, :]`
    
- But **scattered access** (e.g. using `nonzero` or `advanced indexing`) breaks memory coalescing.
    
- `spins[boundary_indices]` is **random** access â€” slow!

---

### 4. **Sparse and conditional updates**

- GPU excels at dense tensor operations.
    
- Updating just a subset of pixels (`spins[mask] = new_spin`) is inherently **serial** if:
    
    - the `mask` varies per item
        
    - the value depends on nontrivial logic

---

### 5. **Dynamic allocation inside GPU kernels**

- Python-side dynamic lists (like `cluster = [(x, y)]`) donâ€™t exist on the GPU.
    
- You canâ€™t just `.append()` inside a GPU kernel.
    
- Preallocating large enough buffers = wasteful and error-prone.

---

### 6. **Small workloads or small batches**

- If your tensor is small (e.g., `L = 32`) or `N` (batch size) is low, the overhead of launching GPU kernels can outweigh the benefits.
    
- CPU may win here, especially for irregular logic.

---

## Real Example: Wolff Algorithm Bottlenecks on GPU

|Step|Good for GPU?|Why?|
|---|---|---|
|Seed spin selection|âœ…|Uniform random access, easy to batch|
|Cluster mask + visited updates|âŒ|Irregular shape, dynamic growth|
|Roll for neighbors|âš ï¸|Causes memory shuffling|
|Conditional inclusion (rand < p)|âŒ|Branching logic per lattice site|
|torch.nonzero() + advanced index|âŒ|Non-contiguous, dynamic-size tensor|
|Spin flipping via mask|âŒ|Sparse write + mismatch in shape|

---

## TL;DR

> **GPUs are awesome at doing the same thing over a big regular grid.** But if your algorithm has **irregular paths, dynamic growth, or sparse updates**, itâ€™ll probably be faster on **CPU**, unless you rework it into a form that hides these patterns.

---

If you want to extract more speed from the Wolff algorithm, you're much better off:

- Using per-lattice loops (batch-level parallelism)
    
- Or porting the cluster update logic to a C++/CUDA extension or Numba

Want to try a Numba version next to compare?

# 7. numba

# 8. Parallelization Scheme

## 8.1 `concurrent.futures.ProcessPoolExecutor`

~~~python 
from concurrent.futures import ProcessPoolExecutor

def my_task(i):
    # ä»»æ„å¤æ‚ä»£ç 
    return i + 42

task_num = 100
core_num = 28

with ProcessPoolExecutor(max_workers=core_num) as executor:
    results = list(executor.map(my_task, range(task_num)))
~~~

## 8.2 `joblib.Parallel`

~~~python 
from joblib import Parallel, delayed

def my_task(i):
    # ä½ çš„å¤æ‚é€»è¾‘
    return i * i  # ç¤ºä¾‹

results = Parallel(n_jobs=100)(delayed(my_task)(i) for i in range(100))
~~~

# 9. code trick

## 9.1 å·¥ä½œæ–‡ä»¶è°ƒåˆ¶ä¸ç®¡ç†

* æ—§æœ‰æ–¹æ¡ˆ
	`name_head + bools`
	ä½¿ç”¨name_headå‘½åç›¸åº”æ–‡ä»¶, ä»¥ä¿è¯æ–‡ä»¶å¯ç®¡ç†. 
	ä½¿ç”¨boolsæ¥é€‰æ‹©è¿è¡Œé…ç½®å’Œç¼©æ”¾å¤§å—code. 
	å·¥ä½œæ–‡ä»¶è°ƒåˆ¶ä¸ç®¡ç†.
0. ä¸€èˆ¬è€Œè¨€, ä¸€ä¸ªprojectå¯ä»¥è¢«åˆ†ä¸ºå‡ ä¸ªéƒ¨åˆ†. å› è€Œæˆ‘ä»¬éœ€è¦globalå’Œlocalåˆ†ç«‹çš„ç®¡ç†æ¨¡å¼
1. è¿™å‡ ä¸ªéƒ¨åˆ†æ‰€è°ƒç”¨çš„åŒ…ã€å…·ä½“å‡½æ•°ã€ç±»ç­‰, æˆ‘ä»¬æ”¾å…¥ä¸€ä¸ªproj_tools.py.
	ä½¿ç”¨ä¸‹åˆ—codeå°†è¯¥.pyæ–‡ä»¶å†…çš„æ‰€æœ‰åå­—å¼•ç”¨, ä¸€èˆ¬è¿™é‡Œä¼šæ˜¯å¼•ç”¨è¿›ä¸€ä¸ª.ipynbæ–‡ä»¶.
~~~python
import importlib
importlib.reload(proj_tools)
from proj_tools import *
~~~
2. åœ¨.ipynbçš„ç¬¬ä¸€ä¸ªblockå†…, åº”è¯¥åŒºåˆ†globalçš„config variableså’Œlocalçš„config variables. 
	global config: 
		date = '20250416'
		project_name = 'filearrangement'
		d = 
		L = 
		...
		name_head = f'{data}{project_name}d{d}L{L}_'
	
	part1 config:
		part1trialidx = 1
		config_variables = 
		part1name_head = f'{name_head}{part1trialidx}{config_variables}' 

## 9.2 è¯»`help(obj)`

20250411, ä»Šå¤©å­¦ä¹ äº†ä¸€ä¸‹é˜…è¯»helpæ–‡æ¡£, å‘ç°è¿˜æ˜¯æœ‰ä¸€äº›ç”¨å¤„çš„.
`help(obj)` è¿”å›çš„æ˜¯`__doc__`attribute, å³ä¸ºdocstring, """ """å†…çš„å†…å®¹.  
å…·ä½“è€Œè¨€, é˜…è¯»äº†`tenpy`çš„`TwoSiteDMRGEngine`çš„`help`æ–‡æ¡£. 
å‘ç°å®ƒçš„ç»“æ„æ˜¯: 
- parameters: å¯¹è±¡çš„ä¼ å…¥ç›´æ¥å‚æ•°. 
- options: å¯¹è±¡çš„ä¼ å…¥é—´æ¥å‚æ•°, ç”¨äºé…ç½®æ•´ä¸ªobj. 
- returns: è¿”å›å€¼.  

## 9.3 debugæ–¹å‘

codingè¿‡ç¨‹ä¸­, æå¤§ä¸€éƒ¨åˆ†é—®é¢˜æ¥è‡ªäºå„ä¸ªç†è®ºä¹‹é—´ç»†èŠ‚configçš„å¯¹é½. ä¸¾ä¾‹è€Œè¨€, fftçš„norm. 

# 10. openMPé—®é¢˜

## ä¸€ã€é—®é¢˜ç°è±¡

- åœ¨è¿è¡ŒåŒ…å« `torch` ä¸ `matplotlib.pyplot` çš„è„šæœ¬æ—¶ï¼ŒæŠ¥é”™ï¼š
    
    vbnet
    
    å¤åˆ¶
    
    `OMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized.`
    
- é”™è¯¯æç¤ºå¤šä¸ª OpenMP è¿è¡Œæ—¶è¢«åŠ è½½ï¼Œå¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™æˆ–ç»“æœä¸æ­£ç¡®ã€‚

---

## äºŒã€åˆæ­¥æ’æŸ¥

1. **æŸ¥çœ‹åŠ è½½çš„ DLL**  
    åœ¨è„šæœ¬ä¸­æ‰“å°è¿›ç¨‹å·²åŠ è½½çš„ DLLï¼Œç­›é€‰åŒ…å« `iomp` æˆ– `omp` çš„æ¡ç›®ã€‚  
    ç»“æœå‘ç°ï¼š
    
    vbnet
    
    å¤åˆ¶
    
    `â€¦\torch\lib\cudnn_engines_precompiled64_9.dll   â€¦\torch\lib\cudnn_engines_runtime_compiled64_9.dll   â€¦\torch\lib\libiomp5md.dll   â€¦\torch\lib\libiompstubs5md.dll`
    
    å…¶ä¸­åä¸¤è€…å‡å±äº Intel OpenMP è¿è¡Œæ—¶ã€‚
    ![[Pasted image 20250416123103.png]]
    å°†ç¬¬äºŒä¸ªå­˜æ ¹dllæ”¹ååä»æ—§æ²¡æœ‰è§£å†³é—®é¢˜
2. **ç¡®è®¤ Matplotlib åç«¯**
    
    python
    
    å¤åˆ¶
    
    `import matplotlib print(matplotlib.get_backend())  # è¾“å‡º tkagg`
    
    è¯´æ˜ä¸æ˜¯ Qt ç»‘å®šå¼•å…¥å†²çªã€‚
    
3. **åˆ†æ­¥å¯¼å…¥å®šä½**  
    åˆ†åˆ«åœ¨ `import torch`ã€`import numpy`ã€`import matplotlib.pyplot` ä¹‹åæ‰“å°æ—¥å¿—ï¼Œç¡®å®šæ˜¯ PyTorch è‡ªå¸¦çš„ OpenMP runtime åœ¨ç¬¬ä¸€æ¬¡å¯¼å…¥æ—¶å°±å·²åˆå§‹åŒ–ã€‚

---

## ä¸‰ã€è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1ï¼šç¯å¢ƒå˜é‡â€œæ‰“è¡¥ä¸â€ï¼ˆæ¨èï¼‰

åœ¨è„šæœ¬æœ€å‰é¢ï¼ˆä»»ä½•åº“ import ä¹‹å‰ï¼‰åŠ å…¥ï¼š

python

å¤åˆ¶

`import os os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"`

- **åŸç†**ï¼šå‘Šè¯‰ Intel OpenMPï¼Œå³ä½¿æ£€æµ‹åˆ°é‡å¤åˆå§‹åŒ–ï¼Œä¹Ÿä¸è¦æŠ¥é”™ï¼Œç»§ç»­æ‰§è¡Œã€‚
    
- **ä¼˜ç‚¹**ï¼šæ— éœ€ä¿®æ”¹ç¯å¢ƒã€DLL æˆ–é‡æ–°ç¼–è¯‘ï¼Œæœ€ç®€å•ç›´æ¥ã€‚
    
- **ç¼ºç‚¹**ï¼šä»æœ‰å¤šé‡ runtimeï¼Œå¯èƒ½ç•¥å¾®å½±å“æ€§èƒ½æˆ–ç¨³å®šæ€§ã€‚

### æ–¹æ¡ˆ 2ï¼šç§»é™¤å­˜æ ¹ DLLï¼ˆæœ‰é£é™©ï¼‰

1. æ‰¾åˆ° PyTorch çš„ DLL ç›®å½•ï¼ˆå¦‚ `â€¦\envs\my_torch\Lib\site-packages\torch\lib\`ï¼‰ã€‚
    
2. å°† `libiompstubs5md.dll` é‡å‘½åæˆ–ç§»å‡ºï¼ˆä¾‹å¦‚æ”¹åä¸º `.bak`ï¼‰ã€‚
    
3. é‡å¯ Python å¹¶æµ‹è¯•è„šæœ¬ã€‚

- **é£é™©**ï¼šå¦‚æœå­˜æ ¹åº“æä¾›äº†å¿…è¦ç¬¦å·ï¼Œå¯èƒ½å¯¼è‡´é“¾æ¥é”™è¯¯æˆ–åŠŸèƒ½å¼‚å¸¸ã€‚

### æ–¹æ¡ˆ 3ï¼šå½»åº•é‡å»ºç¯å¢ƒï¼ˆæç«¯æ–¹æ¡ˆï¼‰

- åœ¨ Linux ä¸‹è‡ªè¡Œç¼–è¯‘ PyTorchï¼Œç¦ç”¨ Intel MKL/OpenMPï¼Œæ”¹ç”¨ GNU OpenMPã€‚
    
- æˆ–å¯»æ‰¾ä¸å¸¦ Intel OpenMP çš„ PyTorch æ„å»ºç‰ˆæœ¬ã€‚

æ­¤æ–¹æ¡ˆå¤æ‚ä¸”è€—æ—¶ï¼Œé€šå¸¸ä¸æ¨èã€‚

---

## å››ã€æœ€ç»ˆæ¨è

> **åœ¨è„šæœ¬æœ€å‰é¢è®¾ç½®**
> 
> python
> 
> å¤åˆ¶
> 
> `import os os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"`
> 
> æ—¢èƒ½å¿«é€Ÿæ¶ˆé™¤æŠ¥é”™ï¼Œåˆä¸ä¼šå¯¹ç°æœ‰ç¯å¢ƒåšä¾µå…¥å¼ä¿®æ”¹ï¼Œæ˜¯æœ€å®ç”¨çš„åº”æ€¥åŠæ³•ã€‚
