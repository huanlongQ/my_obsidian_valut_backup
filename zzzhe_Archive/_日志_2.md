# 20250520

今天完成了答辩, 下一步的计划是讲所有文书工作清理下来: 
- 物院的档案工作 
- 24号的党课集体学习
- 25号截止的毕业论文终稿提交
- 下周一的美政公pre
- 下周一的网球课考试
- 1k字的现代物理前沿讲座(II)小论文
- 美政公考试
- 英语课考试
- 本周五下午陈基老师的讲座

下周还是激情满满的一周啊. 难搞. 

# 20250519

把中科院做cmt计算的那个老师的信息扒一下，去follow一下他们的文章。
你需要有一个thought campus的概念, 以这个东西为基础把书读薄. 
你得有一个mechanism folder, 用各种mechanism降低决策成本. 

# 20250518 

![[Pasted image 20250518182305.png]] 

同时做两个以上project的确是个重要问题，得在下一步工作中学习这个技能，并形成良好的管理机制。

# 20250516

minimind is a repo for llm.

from a perspective of real life, make sense does not matter while we should focus on the sharp gaps. 

对于一个事物, 应当有战略(strategic level)、战役(campaign level)、战术(tactical level)三种级别的认识,
应当有宏观(Macroscopic level)、介观(Mesoscopic level)、微观(Microscopic level)三种级别的认识. 
举例而言, 一个世纪级别的趋势, 和一个十年级别的趋势和一个一年级别的趋势是完全不一样的. 

# 20250507

papercoder

# 20250506

同学您好，虽然我也完全不会踢毽子，甚至还踢抽筋了😓，但是我想推荐本书，《刻意练习》
我觉得这个书可能对您练习体育运动时有所启发。

不要猜别人院系，不要猜别人地区。
最重要的是，不要当面猜！
我得有一个工具箱，用于沟通交流。
这个工具箱得有抓手，得有抓手，得有抓手。是的，我必须对齐对方的channel， 对齐对方的channel。
主要的抓手是对方的生活内容。

政治学入门：李军教授（中国政法大学）的政治学入门+心理学

# 20250505

得看人下菜碟. 
得兼容对方的价值观, 兼容对方的思维体系. 
得对齐channel, 不能channel分层. 

跟师姐说话注意分寸，不能提及体重等敏感话题。
跟卓成师兄说话不要跟他较真。
要少说话，做一个厚重的人。多做事，少说话。只说震耳欲聋的话。

怎么提升激活函数的量？

# 20250425

在面试技能分享讲座这个方面, 大获全胜. 几乎$\frac{1}{4}$的学生都在讲座之后加了微信. 
可以很明确地讲, 所谓的表达优质、所谓的信心, 真的就是有货就OK, 没活就整不起来活儿. 
另外, 看似具有领袖气质的人, 在面对他们无法解决的问题时, 也是怂得要死. 真正在全局问题上具有领袖气质的人, 首先是打铁自身硬, 对自己足够狠, 能够保持一个可怕的工作方式. 

# 20250423 

试试小波变换呗, 小波变换进行RG. 

# 20250422

事实上, 情况有点糟糕......
我这里的结果不算很好.......
下一步是得把时间压榨一下. 

乐, 只要敢于调window, 什么值都能求出来是吧.....乐死我了

AT_fft有了
Ising_fft和Ising_real有了
xy_fft和xy_real都失败了

# 20250421

整理一下要写的ppt的内容

$$
\mathrm{you} \in (\mathbf{}{街头混混, 保险销售})
$$
算是完成了吧, 现在接下来的任务是将心态处理好. 

# 20250419

1d TFIM是怎么一回事: 

## 🔢 1. 模型回顾

1D TFIM 的 Hamiltonian：

H=−J∑iσizσi+1z−h∑iσixH = -J \sum_{i} \sigma_i^z \sigma_{i+1}^z - h \sum_i \sigma_i^xH=−Ji∑​σiz​σi+1z​−hi∑​σix​

- JJJ：最近邻自旋耦合；
    
- hhh：横向磁场；
    
- 这是一个量子模型，对称性是 Z2\mathbb{Z}_2Z2​。

---

## 🧠 2. 可以做 RG 吗？有哪些方法？

是的！1D TFIM 可以做 RG，而且有多种方式：

---

### ✂️ (1) **Kadanoff Block RG（近似解法）**

Kadanoff 的思想是把多个格点（比如 2 个）合并为一个“block”，再重写有效 Hamiltonian，并投影回低能子空间。步骤如下：

1. 把链分成小块，比如 2 个格点一组；
    
2. 对每个 block 解哈密顿量，保留低能态（比如只保留两个本征态）；
    
3. 用这些低能态构造一个新的有效自旋系统；
    
4. 得到新的耦合 J′J'J′、场 h′h'h′，建立 RG 变换；
    
5. 观察它在重复 RG 之后是否流向某个 fixed point。

优点：直观、有启发性  
缺点：近似粗糙，尤其量子纠缠处理不准确。

---

### ⚙️ (2) **量子通用 RG：Strong-Disorder RG（SDRG）**

对于 TFIM 的一种推广（比如引入无序），Fisher 曾用 Strong Disorder RG 解出了整个临界行为（非常漂亮！）：

- 逐步找到最大的局域项（比如最大的 hih_ihi​ 或 JiJ_iJi​）；
    
- 根据哪个最大来进行有效“局域对角化”或“合并”；
    
- 每一步都简化系统规模；
    
- 在无限迭代后，可以得到精确的临界指数。

**在这套方法下：**

- TFIM 在临界点具有：
    
    ν=2,z=∞（无序时）\nu = 2, \quad z = \infty \quad \text{（无序时）}ν=2,z=∞（无序时）

---

### 🔄 (3) **映射到 2D 经典 Ising 模型 + 经典 RG**

这一步特别关键：

- 1D TFIM 可通过 Trotter decomposition 映射为 **2D 经典 Ising 模型**；
    
- 从而，我们可以用 2D Ising 的 RG 方法（如 Wilson RG）来研究 1D TFIM；
    
- 这也是 TFIM 临界指数 ν=1\nu = 1ν=1、z=1z = 1z=1、β=1/8\beta = 1/8β=1/8 等的由来。

这种 RG 是在 path integral 或 transfer matrix 层面做的。

---

### 🌊 (4) **现代数值 RG：DMRG / Tensor RG**

你应该已经熟了——现代对 1D TFIM 最主流的 RG 方法是：

- **DMRG（Density Matrix Renormalization Group）**：保留纠缠最多的基底，适用于基态性质。
    
- **Tensor Network RG（如 TRG、MERA）**：尤其 MERA，非常适合描述临界系统。

这些方法都可用于数值求解 TFIM 的临界行为，而且可以分析纠缠熵的标度行为（对数标度、中心荷等）。

---

## 📈 3. TFIM 的临界行为 via RG

当你对 TFIM 做 RG 分析时，你会得到如下关键结果：

|指标|值|
|---|---|
|临界点|hc=Jh_c = Jhc​=J|
|动力学指数|z=1z = 1z=1|
|相关长度指数|ν=1\nu = 1ν=1|
|序参量指数|β=1/8\beta = 1/8β=1/8|
|中心荷（纠缠熵标度）|c=1/2c = 1/2c=1/2|

你用不同方法（解析 RG、映射、数值 DMRG）都可以得到这些结果，说明它们是普适性的表现。

1. **基于矩阵积态（MPS）数据的量子相变分类**
    
    - **项目目标**：利用机器学习模型自动识别 1D 横场伊辛模型（TFIM）不同相区（顺磁态／铁磁态）。
        
    - **方法论**：
        
        1. 用 TenPy 或 Google TensorNetwork 生成不同参数 h/Jh/Jh/J 下的 MPS 基态，提取局部或全局张量数据（如  分解后的奇异值、局域密度矩阵熵等）。
            
        2. 构造特征向量（e.g. 熵谱、张量范数、相邻站点关联函数）作为 ML 输入。
            
        3. 训练一个简单的分类器（如 SVM、随机森林或小型全连接神经网络），对相区进行监督学习。

        - **工具**：Python、TenPy、Scikit‑learn、NumPy、Matplotlib
            
        - **预期成果**：
            
            - 不同相区下的特征可视化；
                
            - 模型准确率、混淆矩阵；
                
            - 分析哪些特征最能区分相变前后。
                
2. **基于受限玻尔兹曼机（RBM）的神经网络量子态（NQS）重现小体系基态**
    
    - **项目目标**：用 RBM 表示并优化 1D XXZ 链或小型 Hubbard 模型的基态，评估与精确对角结果的误差。
        
    - **方法论**：
        
        1. 定义 RBM 量子态波函数 Ψ(σ)=∑{h}e∑iaiσi+∑jbjhj+∑i,jWijσihj\Psi(\sigma) = \sum_{\{h\}} e^{\sum_i a_i \sigma_i + \sum_j b_j h_j + \sum_{i,j} W_{ij} \sigma_i h_j}Ψ(σ)=∑{h}​e∑i​ai​σi​+∑j​bj​hj​+∑i,j​Wij​σi​hj​。
            
        2. 用变分蒙特卡洛（VMC）结合梯度下降训练 RBM 参数，使能量期望最小。
            
        3. 与 Exact Diagonalization（用 QuSpin 或自写小程序）结果对比。
            
    - **工具**：NetKet 或自己搭 VMC＋PyTorch、QuSpin、NumPy
        
    - **预期成果**：
        
        - 随基态能量随训练迭代的收敛曲线；
            
        - 与精确基态能量的误差随体系大小的变化；
            
        - 对 RBM 结构（隐藏单元数、学习率）的敏感性分析。
            
3. **自编码器（Autoencoder）在量子多体波函数降维与异常检测中的应用**
    
    - **项目目标**：利用深度自编码器对小型 1D 自旋链 MPS 张量进行降维，探索潜在空间能否自动分离相区或检测相变临界点。
        
    - **方法论**：
        
        1. 准备大量不同 h/Jh/Jh/J 下的 MPS 张量或 QMC Spin Snapshot 数据。
            
        2. 设计对称自编码器，将输入降到低维潜在向量，再重构输出。
            
        3. 在潜在空间中可视化（t‑SNE、PCA）不同相区的分布，寻找“分界”。
            
    - **工具**：PyTorch／TensorFlow、Scikit‑learn、TenPy、Matplotlib
        
    - **预期成果**：
        
        - 潜在空间图；
            
        - 重构误差随参数 h/Jh/Jh/J 的变化曲线；
            
        - 定性评估能否以无监督方式探测相变。
            
4. **强化学习优化 DMRG 收敛路线**
    
    - **项目目标**：用强化学习（RL）智能地选择 DMRG 中的截断误差阈值或保留维度，提升收敛速度并控制误差。
        
    - **方法论**：
        
        1. 将 DMRG 迭代步骤视为 Markov 决策过程：状态为当前截断误差和能量梯度，动作为空间维度增减或调整截断误差。
            
        2. 采用 Q‑learning 或 Policy Gradient（e.g. PPO）训练智能体，奖励函数结合能量下降速率和计算开销。
            
        3. 在小型 1D Hubbard 或 TFIM 上测试性能提升。
            
    - **工具**：Python、TenPy、Stable‑Baselines3、NumPy
        
    - **预期成果**：
        
        - 与手动调参 DMRG 的收敛步数／时间对比；
            
        - RL 策略在不同模型参数下的泛化能力评估。
            
5. **图神经网络（GNN）预测量子体系基态能量**
    
    - **项目目标**：用图神经网络根据自旋链的相互作用图结构快速预估基态能量，作为近似或初始化。
        
    - **方法论**：
        
        1. 将自旋体系（节点：自旋，边：耦合常数）构造成图数据。
            
        2. 构建 GCN、GAT 或 GraphSAGE，输入图后输出标量—能量预测。
            
        3. 用精确对角或 DMRG 结果训练／测试模型。
            
    - **工具**：PyTorch Geometric、NumPy、TenPy（生成标签）
        
    - **预期成果**：
        
        - 能量预测误差随体系大小的变化；
            
        - 不同 GNN 架构的性能对比；
            
        - 分析 GNN 是否能学到物理规律（可解释性探索）。

---

**选题建议**：

- 若偏重“快速上手＋结果可视化”，可选（1）或（3）；
    
- 若想深挖“神经网络量子态”前沿，可选（2）；
    
- 若想挑战“元学习／智能控制”算法，可选（4）；
    
- 若想结合“图论与量子”新兴交叉，可选（5）。

6. **基于自旋快照的卷积神经网络（CNN）相区划分**
    
    - **项目目标**  
        利用 Monte Carlo 采样得到的自旋配置图像（spin snapshot）直接训练 CNN，自动识别不同相区（如顺磁／铁磁、BKT 相变等）。
        
    - **方法论**
        
        1. 用 Metropolis 或 Wolff 算法生成大量不同温度下的自旋快照，保存为二维二值图。
            
        2. 设计简单的 CNN（例如两层卷积＋两层全连通），以图像为输入，输出相区标签。
            
        3. 评估模型在临界点附近的分类效果，并可视化中间特征图（feature map）。
            
    - **工具**  
        Python、PyTorch、NumPy、Matplotlib、任意 Monte Carlo 库（TenPy 自带或自写）。
        
    - **预期成果**
        
        - 不同温度下分类准确率曲线；
            
        - Saliency map 或 Grad‑CAM 展示网络关注区域；
            
        - 总结 CNN 在不同系统（Ising／XY）上的泛化能力。
            
7. **生成对抗网络（GAN）重构量子态**
    
    - **项目目标**  
        使用 GAN 生成符合给定哈密顿量统计性质的自旋配置，并与真实 Monte Carlo 数据对比，探究能否用生成模型“学习”物理分布。
        
    - **方法论**
        
        1. 选定 Ising 模型或简单 Hubbard 模型，以 Monte Carlo 样本训练一个 DCGAN。
            
        2. 判别器学习区分真／假配置，生成器学习产生“物理正确”的配置。
            
        3. 用物理指标（能量分布、自关联函数等）评估生成样本的质量。
            
    - **工具**  
        Python、PyTorch（torchvision GAN 模块）、NumPy、TenPy 或 NetKet（标签生成）。
        
    - **预期成果**
        
        - GAN 训练损失曲线；
            
        - 热力学量的对比分布图；
            
        - 分析 GAN 模型学习到的物理规律。
            
8. **物理信息神经网络（PINN）求解时间演化**
    
    - **项目目标**  
        使用 PINN（Physics‑Informed Neural Network）求解 1D 自旋链在某简单哈密顿演化下的时变波函数或期望值，为传统数值方法提供近似解。
        
    - **方法论**
        
        1. 将薛定谔方程残差作为 PINN 的损失项之一，并结合边界／初始条件。
            
        2. 设计一个小型多层感知机，输入 (x,t)(x,t)(x,t)，输出波函数实部／虚部或局域期望。
            
        3. 与 TEBD、Runge–Kutta 等传统数值解对比精度与速度。
            
    - **工具**  
        Python、TensorFlow 或 PyTorch、自动微分库、NumPy。
        
    - **预期成果**
        
        - PINN 收敛过程中的残差曲线；
            
        - 在有限时间窗口的解与 TEBD 结果对比图；
            
        - 探讨 PINN 在量子演化中的可行性与局限。
            
9. **图自编码器检测拓扑相**
    
    - **项目目标**  
        针对具有拓扑序的量子系统（如 Kitaev 链、SSH 模型），用图自编码器（Graph Autoencoder）在潜在空间中分离不同拓扑相。
        
    - **方法论**
        
        1. 将量子格点与跃迁耦合映射为图结构（节点属性可用局域态或能带信息）。
            
        2. 构建 GAE，将图编码为潜在向量，再解码重构邻接矩阵或其它物理量。
            
        3. 在潜在空间中用聚类算法（如 K‑means）区分不同拓扑相，评估分界是否清晰。
            
    - **工具**  
        Python、PyTorch Geometric、Scikit‑learn、TenPy（生成标签和哈密顿矩阵）。
        
    - **预期成果**
        
        - 潜在空间降维可视化；
            
        - 聚类准确率／轮廓系数分析；
            
        - 讨论 GAE 在无监督发现拓扑相中的优势与缺陷。
            
10. **混合量子‑经典变分模型（VQC＋NN）**
    
    - **项目目标**  
        利用仿真模拟的变分量子电路（Variational Quantum Circuit, VQC）输出与经典神经网络联合，提升小体系基态能量预测精度。
        
    - **方法论**
        
        1. 用 Qiskit 或 Pennylane 构建小规模 VQC，参数化旋转门学习哈密顿量基态。
            
        2. 将量子电路输出的测量值（如几组 Pauli 测量结果）作为特征，输入一个小型 NN 做进一步后处理或回归能量。
            
        3. 与纯经典 NN、纯 VQC 方法对比性能。
            
    - **工具**  
        Python、Qiskit/Pennylane、PyTorch、NumPy。
        
    - **预期成果**
        
        - 量子＋经典模型能量误差曲线；
            
        - 参数数量与训练稳定性分析；
            
        - 探讨混合模型在 NISQ 时代的实际应用潜力。
            
11. **时序模型（LSTM／Transformer）预测量子动力学**
    
    - **项目目标**  
        用循环神经网络（LSTM）或 Transformer 架构，基于已知时间序列的局域关联函数或能量，预测下一时刻的系统演化。
        
    - **方法论**
        
        1. 先用 TEBD、QMC 或 Exact Diagonal 生成一系列离散时间步的数据集：如自旋对关联、能量、磁化强度。
            
        2. 训练 LSTM/Transformer 预测未来若干步的物理量序列。
            
        3. 评估预测误差随预测步数的增长情况，并分析模型能否“捕捉”物理记忆效应。
            
    - **工具**  
        Python、PyTorch、NumPy、TenPy（数据生成）。
        
    - **预期成果**
        
        - 预测 vs 真值的对比曲线；
            
        - 不同模型架构／超参对预测性能的影响；
            
        - 关于记忆长度与物理相关性的讨论。
            
12. **强化学习自动发现最优哈密顿量参数**
    
    - **项目目标**  
        将一类多体哈密顿量（如 XXZ 链的 Δ\DeltaΔ 参数、外场强度）参数搜索问题视为 RL 任务，自动寻找能产生目标性质（如最大纠缠、指定能隙）的参数组合。
        
    - **方法论**
        
        1. 定义环境：状态为当前参数与对应一小段 DMRG/ED 结果（能量、纠缠熵等），动作为在参数空间作微调。
            
        2. 用 Q‑learning 或 Policy Gradient（PPO/SAC）训练智能体，使其在最少步数内找到满足指定标准的参数。
            
        3. 验证在不同模型规模或初始值下的泛化能力。
            
    - **工具**  
        Python、Stable‑Baselines3、TenPy/QuSpin、NumPy。
        
    - **预期成果**
        
        - 智能体收敛曲线；
            
        - 与网格搜索或 Bayesian 优化方法的效率对比；
            
        - 讨论 RL 在物理参数搜寻中的可行性与瓶颈。

---

**建议**：

- 挑选时可结合你熟悉的仿真手段（MPS/DMRG、QMC、ED）与想深入的机器学习模型（CNN、GAN、PINN、GNN、RL、时序模型等）；
    
- 考虑项目规模与时间成本，优先保证核心算法实现与结果可视化，再深入性能分析与物理解释；
    
- 如果想快速出结果，可选（6）、（7）或（11）；若想挑战前沿算法，可以考虑（9）、（10）或（12）。

# 20250418

没有其他问题了, 现在最大的毛病还是摸鱼过度. 

给李强审论文, 有几个问题: 
1. 为什么随着速度的变化, 这个微孔的间距、直径呈现先增后减的趋势
2. 你用了什么不同的方案导致了这个gap, 为什么别人没有做出来, 这个需要分析
3. 你有没有在沿着速度方向和垂直于速度方向进行切割, 调研bubble在xy方向的特征. 我猜测这个bubble可能不是正圆, 在平行垂直速度方向应该有区别
4. 可能是动力学过程中的凸起把激光聚焦了, 这就要分析毁伤的动力学过程了
5. 得看一眼, 谷底位置是否真的是没有被烧凸的, 有可能谷底也被抬高了一丢丢

李强给了一堆建议
1. 心气要变强大
2. 身体要好

# 20250417

今天尝试了各个尺度的RG+NN方法. 发现效果尚可, 基本上能够把值给算出来. 

下一步的动作, 是将这个方案移置到**XY q Potts, AT**等模型上

$$
\frac{\partial n_e}{dt}=A_3(qI(t))^3
$$

$$
n(t)=e^{\gamma(t)}\left[\left(\frac{4\ln2}{\pi}\right)^{3/2}A_3\left(\frac{qF}{\tau_L}\right)^3\int_{-\infty}^te^{-3a^2x^2-\gamma(x)}dx+n_0\right]
$$
$$
\gamma(z)=(q\alpha F/2)[\mathrm{erf}(az)+1],a=2\sqrt{\ln2}/\tau_{L}
$$
$$
r_{MP}=r_{R}/\sqrt{n}
$$

# 20250416

今天早上搞完了体侧, 体质确实有所下降. 好在21级体测崩掉不会不给毕业. 

开始工作方面. 我仍旧是发现今天开始工作的时候非常难受, 不想继续做下去. 
归根结底在于我给自己早上留的任务是一个相对而言有开创性的任务, 需要大量细致的决策才能完成. 如果我每天晚上给第二条留的是一个非开创性的任务, 相对而言只需要循规蹈矩就可以得到结果, 那可能会更好. 

那么, 要不我先去看看fft思路的方案怎么搞, 并且把ml测试一下. 

# 20250415

今天似乎是国家安全日. 
用fft做model, 绝对是一个极其好的方案, 绝对是一个极其好的方案! 低频分量>>高频分量->低温相, 高频分量>>低频分量->高温相. 妙哉妙哉呀! 

现在, 已经有7k字左右的内容了. 接下来, 我们需要余下的5k字的内容. 这5k字的内容需要1~2k字用于介绍RG+reweight+ML的结合. 再加上1k Ising, 1k q states potts, 1k XY model. 这就已经完成了. 
太棒了. 

这里是剩余的还没有完成的内容, 预计合起来应该有2k字(比较困难, 得好好扩写)左右喽. 

~~~
% 缺一个对k空间rg的理论介绍. 1k字
% 缺一个对mc histogram reweight方法这个histogram的含义的介绍. 200字
% 缺一个mc histogram reweight方法的现代发展. 200~500字
% 缺一个对其他model的histogram reweight局限性的分析. 100字
% 缺一个对histogram reweight是数值模拟与物理理论的巧妙结合的分析. 100字
~~~

综上所述, 整个15k字数还是轻轻松松的. 
额, 发现从不同途径进行统计得到的字数统计差距还是非常巨大的, 所以我需要好好做个整理呀. 

事实上,进行一定量的分配后, 每个任务都没有多大啊. 

# 20250414

今天给zlj祝个生日快乐. 好的, 极好的. 
今天又写了几千字论文，很不错的，大概明后两天就能将所有内容写完。
明天需要写完rg，rg大概写了2k字，要不还是把rg再多写1k字？reweight至少也要写2k以上才行，甚至得写3k，和各个具体的model，各个model分别得写1k字 ising1k，potts 1k xy 1k。
除此之外，没有除此之外nm的。

# 20250413 

很好的, 今天进行了很好的心理学思考, 考察了我应该怎么建立本能的问题. 

又一个重大问题的发现在于, 我把每天夜晚回到宿舍后的时间**定义**为了**休闲娱乐时间**, 这个明确的定义产生了明显的锚定效应, 使得我不得不过分休闲娱乐. 实际上, 这是完全不必要的. 正确的方案是我应当在有事情可休闲娱乐的时候进行休闲娱乐, 没有事情进行休闲娱乐的时候就不休闲娱乐. 
还有就是, 讲得对, 应当在正常事务之外有一个支线副线进行受益、成长. 这个副线可以是**自媒体**, 可以是**财经类知识**, 可以是**心理学知识**, 这些都可以. 总之得有一个物理学之外的副线. 

此外, 限制我现在工作效率的最大因素不是别的, 就是**项目文件版本管理**问题, 在这个问题上, 我去跟其他任何书籍学习什么方法论层面的技巧都是空的, 我需要的是战术性的解决方案, 是trick级别的解决方案. 就比如之前我记录过的name_head这个东西, 很傻逼很简单的战术, 但是极其好用. 配套这个战术的各项规则, 也是一样, 结合到这里面来, 就一定会豁然开朗. 

以后, 解决一个问题的时候, 我要首先记得进行**战役战术规划**.  

- **必须有一段时间用来学外语, 周期性地学习, 随用随学习, 这会好的. 一个可用的思路是利用欧路词典的特性, 收集历史记录和收藏记录, 然后找时间一波全收录起来.** 
	是的, 具体的战役战术级操作应该是, 将一堆词汇汇总起来, 放到一个外语学习的Project里面, 然后把

# 20250410

总结前后，发现我现在对旧事的心结主要集中在浪费了4年的大好时光。
我可以告诉自己，这样的时光是很正常的，我的姿势水平让我走到这一步是很natural的，是必然的。但是这是相对弱势的态度。正确的方案应当是把失去的时间抢回来。
那么，我就必须布局自己应当在未来做到的几件事情。
1. 把表达能力练出来。普通话要搞定，语句的逻辑更要搞定, 怒火要用山东话来表达。
2. 把财经知识层面练出来，为未来a股暴涨时期发财做好准备。
3. 可以开始谋划布局做个自媒体的事情了。
除此之外，我想未来进行这样的分析也成为一种必要，非常好的必要。
另外，我意识到必要的对高质量博主的信息收集还是必要的，我得想办法处理这个问题。对各类信息博主的信息管理也成为一种必要。我需要在毕业后完成这一点。

***我现在的焦虑有一点，是不知道毕业论文80分的难度到底到什么程度，这个需要去做个调查*** 

# 20250331

- i should know eaning of bond dim.
- and complexity of mps
- today i find that to realize a specific project is much more harder than just project it. i should take lessons from military establishment, to emphasis action. i should read military related books. 

# 20250330

- According to today's practice, the outside broder/inside broder regime works well. 
- I learnt the DMRG, MPO, MPS, TEBD algos. They gives me a clear look for the computation condensed matter area. Tensor Network method is really nice. 
- Yesterday, a truth shocked me that the grand leader Chen Jining had time to pave the campus of Tsinghua with his wife. He, even he, has leisure time. I should find a right pattern for my life too. 

# 20250329

Eisenhower使用了重要/不重要，紧急/不紧急的四分方法处理事务，我应该加一个，采用边界外/边界内维度。
事实上，应该说边界外/边界内维度就是重要/不重要维度的一种体现，只不过对我个人更加适用了。我的下一步，是首先将这种方法沉淀下来，压入我的本能习惯。
